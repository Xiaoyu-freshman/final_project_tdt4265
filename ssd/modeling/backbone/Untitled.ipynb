{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class BasicModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This is a basic backbone for SSD.\n",
    "    The feature extractor outputs a list of 6 feature maps, with the sizes:\n",
    "    [shape(-1, output_channels[0], 38, 38),\n",
    "     shape(-1, output_channels[1], 19, 19),\n",
    "     shape(-1, output_channels[2], 10, 10),\n",
    "     shape(-1, output_channels[3], 5, 5),\n",
    "     shape(-1, output_channels[3], 3, 3),\n",
    "     shape(-1, output_channels[4], 1, 1)]\n",
    "     where \"output_channels\" is the same as cfg.BACKBONE.OUT_CHANNELS\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        #print('hello!, here is the def_init_')\n",
    "        image_size = cfg.INPUT.IMAGE_SIZE\n",
    "        #print('image_size=',image_size)\n",
    "        output_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS\n",
    "        #print('output_channel=',output_channels)\n",
    "        self.output_channels = output_channels\n",
    "        image_channels = cfg.MODEL.BACKBONE.INPUT_CHANNELS\n",
    "        #print('image_channels=',image_channels)\n",
    "        self.output_feature_size = cfg.MODEL.PRIORS.FEATURE_MAPS\n",
    "        #print('self.output_feature_size=',self.output_feature_size)\n",
    "    #Define the structure\n",
    "    #1.Classical VGG\n",
    "        base=[]\n",
    "        base.append(torch.nn.Conv2d(in_channels=image_channels, out_channels=64,kernel_size=3,stride=1,padding=1))\n",
    "        base.append(torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        base.append(torch.nn.ReLU())\n",
    "        base.append(torch.nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,stride=1,padding=1))\n",
    "        base.append(torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        base.append(torch.nn.ReLU())\n",
    "        base.append(torch.nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride=1,padding=1)) \n",
    "        base.append(torch.nn.ReLU())\n",
    "        base.append(torch.nn.Conv2d(in_channels=128, out_channels=256,kernel_size=3,stride=2,padding=1)) #output[0]\n",
    "        base.append(torch.nn.ReLU())\n",
    "        self.base = torch.nn.Sequential(*base)\n",
    "    #2. extra_layers (ReLU will be used in the foward function)\n",
    "        extra_layer=[]\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=256,kernel_size=3,stride=1,padding=1))\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=512,kernel_size=3,stride=2,padding=1)) #ouput[1]\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=512, out_channels=512,kernel_size=3,stride=1,padding=1))\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=512, out_channels=256,kernel_size=3,stride=2,padding=1)) #output[2]\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=256,kernel_size=3,stride=1,padding=1))\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=256,kernel_size=3,stride=2,padding=1)) #output[3]\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=256,kernel_size=3,stride=1,padding=1))\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=128,kernel_size=3,stride=2,padding=1))  #output[4]\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=128, out_channels=256,kernel_size=3,stride=1,padding=1))\n",
    "        #need ReLU\n",
    "        extra_layer.append(torch.nn.Conv2d(in_channels=256, out_channels=128,kernel_size=3,stride=2,padding=0))  #output[5]\n",
    "        #need ReLU\n",
    "        self.extra_layer=torch.nn.Sequential(*extra_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward functiom should output features with shape:\n",
    "            [shape(-1, output_channels[0], 38, 38),\n",
    "            shape(-1, output_channels[1], 19, 19),\n",
    "            shape(-1, output_channels[2], 10, 10),\n",
    "            shape(-1, output_channels[3], 5, 5),\n",
    "            shape(-1, output_channels[3], 3, 3),\n",
    "            shape(-1, output_channels[4], 1, 1)]\n",
    "        We have added assertion tests to check this, iteration through out_features,\n",
    "        where out_features[0] should have the shape:\n",
    "            shape(-1, output_channels[0], 38, 38),\n",
    "        \"\"\"\n",
    "        #print('hello, this is the forward')\n",
    "        out_features = []\n",
    "        #The output from the base,i.e. output[0]\n",
    "        x=self.base(x)\n",
    "        out_features.append(x)\n",
    "        #For other outputs:\n",
    "        for i, f in enumerate(self.extra_layer): #i means the index and f means the function of the layer\n",
    "            if i== len(self.extra_layer):\n",
    "                x= f(x)\n",
    "            else:\n",
    "                x= torch.nn.functional.relu(f(x),inplace=True)\n",
    "            if i % 2 == 1:\n",
    "                out_features.append(x)\n",
    "                #print('layer:',f)\n",
    "        #print('out_features',out_features[0].shape)\n",
    "            \n",
    "#         for idx, feature in enumerate(out_features):\n",
    "#             out_channel = self.output_channels[idx]\n",
    "#             feature_map_size=self.output_feature_size[idx]\n",
    "#             #print('out_channel',feature.shape[1:])\n",
    "#             expected_shape = (out_channel, feature_map_size, feature_map_size)\n",
    "#             assert feature.shape[1:] == expected_shape, \\\n",
    "#                 f\"Expected shape: {expected_shape}, got: {feature.shape[1:]} at output IDX: {idx}\"\n",
    "        return tuple(out_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/xyzhu/.cache/torch/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb0ac0d4e4f448c9c3d59bbe01522b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vgg_16=torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e8c9cba4ac23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBasicModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cfg'"
     ]
    }
   ],
   "source": [
    "test=BasicModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ssd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e19be4ba0692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_head\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSDBoxHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ssd'"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from ssd.modeling.backbone.vgg import VGG\n",
    "from ssd.modeling.backbone.basic import BasicModel\n",
    "from ssd.modeling.box_head.box_head import SSDBoxHead\n",
    "from ssd.utils.model_zoo import load_state_dict_from_url\n",
    "from ssd.modeling.backbone.resnet_base import ResNetBase\n",
    "from ssd import torch_utils\n",
    "\n",
    "class SSDDetector(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = build_backbone(cfg)\n",
    "        self.box_head = SSDBoxHead(cfg)\n",
    "        print(\n",
    "            \"Detector initialized. Total Number of params: \",\n",
    "            f\"{torch_utils.format_params(self)}\")\n",
    "        print(\n",
    "            f\"Backbone number of parameters: {torch_utils.format_params(self.backbone)}\")\n",
    "        print(\n",
    "            f\"SSD Head number of parameters: {torch_utils.format_params(self.box_head)}\")\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        features = self.backbone(images)\n",
    "\n",
    "        detections, detector_losses = self.box_head(features, targets)\n",
    "        if self.training:\n",
    "            return detector_losses\n",
    "        return detections\n",
    "\n",
    "\n",
    "def build_backbone(cfg):\n",
    "    backbone_name = cfg.MODEL.BACKBONE.NAME\n",
    "    print(backbone_name)\n",
    "    if backbone_name == \"basic\":\n",
    "        model = BasicModel(cfg)\n",
    "        return model\n",
    "    if backbone_name == \"vgg\":\n",
    "        model = VGG(cfg)\n",
    "        if cfg.MODEL.BACKBONE.PRETRAINED:\n",
    "            state_dict = load_state_dict_from_url(\n",
    "                \"https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\")\n",
    "            model.init_from_pretrain(state_dict)\n",
    "    if backbone_name == \"resnet\":\n",
    "        model_urls = {\n",
    "            'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "            'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "            'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "            'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "            'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',}\n",
    "        name_dict = {18: 'resnet18', 34: 'resnet34', 50: 'resnet50', 101: 'resnet101', 152: 'resnet152'}\n",
    "        layers_dict = {18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], \n",
    "                       101: [3, 4, 23, 3], 152: [3, 8, 36, 3]}\n",
    "        block_dict = {18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck}\n",
    "        model = resnet_base(cfg)\n",
    "        depth = cfg.MODEL.BACKBONE.DEPTH\n",
    "        model = ResNetBase(block_dict[depth], layers_dict[depth],1, **kwargs)\n",
    "        if cfg.MODEL.BACKBONE.PRETRAINED:\n",
    "            state_dict = load_state_dict(model_zoo.load_url(model_urls[name_dict[depth]]))\n",
    "            model.init_from_pretrain(state_dict)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
